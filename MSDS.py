import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from openpyxl.drawing.image import Image as XLImage
from openpyxl.styles import Alignment
from openpyxl.utils.dataframe import dataframe_to_rows
from PIL import Image as PILImage
import io
import re
import gc
import numpy as np
import os
import fitz  # PyMuPDF

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MSDS ìŠ¤ë§ˆíŠ¸ ë³€í™˜ê¸°", layout="wide")
st.title("MSDS ì–‘ì‹ ë³€í™˜ê¸° (PDF ì •ë°€ íŒŒì‹±)")
st.markdown("---")

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ì´ë¯¸ì§€ ì²˜ë¦¬
# --------------------------------------------------------------------------
def normalize_image(pil_img):
    try:
        if pil_img.mode in ('RGBA', 'LA') or (pil_img.mode == 'P' and 'transparency' in pil_img.info):
            background = PILImage.new('RGB', pil_img.size, (255, 255, 255))
            if pil_img.mode == 'P': pil_img = pil_img.convert('RGBA')
            background.paste(pil_img, mask=pil_img.split()[3])
            pil_img = background
        else:
            pil_img = pil_img.convert('RGB')
        return pil_img.resize((32, 32)).convert('L')
    except:
        return pil_img.resize((32, 32)).convert('L')

def get_reference_images():
    img_folder = "reference_imgs"
    ref_images = {}
    if not os.path.exists(img_folder): return {}, False
    try:
        file_list = sorted(os.listdir(img_folder)) 
        for fname in file_list:
            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.tif', '.tiff')):
                full_path = os.path.join(img_folder, fname)
                try:
                    pil_img = PILImage.open(full_path)
                    ref_images[fname] = pil_img
                except: continue
        return ref_images, True
    except: return {}, False

def find_best_match_name(src_img, ref_images):
    best_score = float('inf')
    best_name = None
    try:
        src_norm = normalize_image(src_img)
        src_arr = np.array(src_norm, dtype=np.int16)
        for name, ref_img in ref_images.items():
            ref_norm = normalize_image(ref_img)
            ref_arr = np.array(ref_norm, dtype=np.int16)
            diff = np.mean(np.abs(src_arr - ref_arr))
            if diff < best_score:
                best_score = diff
                best_name = name
        if best_score < 65: return best_name
        else: return None
    except: return None

def extract_number(filename):
    nums = re.findall(r'\d+', filename)
    return int(nums[0]) if nums else 999

# --------------------------------------------------------------------------
# [ì‹ ê·œ í•¨ìˆ˜] PDF ì„¹ì…˜ íŒŒì‹± (í•œ ì¤„ì”© ì½ê¸°)
# --------------------------------------------------------------------------
def parse_pdf_ghs_section(doc):
    """
    PDFë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ìœ í•´ì„± ë¶„ë¥˜(B20)ì™€ Pì½”ë“œ ì„¹ì…˜(ì˜ˆë°©,ëŒ€ì‘,ì €ì¥,íê¸°)ì„ ë¶„ë¦¬í•¨
    """
    full_text_lines = []
    for page in doc:
        # ì¤„ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
        text = page.get_text("text")
        lines = text.split('\n')
        full_text_lines.extend(lines)

    # ë°ì´í„° ì €ì¥ì†Œ
    extracted_data = {
        "hazard_classification": [], # B20 ë‚´ìš©
        "prevention": [],
        "response": [],
        "storage": [],
        "disposal": [],
        "h_codes": [] # ì „ì²´ Hì½”ë“œ
    }

    # ìƒíƒœ í”Œë˜ê·¸
    mode = None  # None -> 'hazard_cls' -> 'label_elements'
    p_section = None # 'prevention', 'response', 'storage', 'disposal'
    
    # í‚¤ì›Œë“œ ì •ë¦¬ (ê³µë°± ì œê±° í›„ ë¹„êµìš©)
    KEY_HAZARD_START = "ìœ í•´ì„±Â·ìœ„í—˜ì„±ë¶„ë¥˜" # ê°€. ìœ í•´ì„±...
    KEY_LABEL_START = "ì˜ˆë°©ì¡°ì¹˜ë¬¸êµ¬" # ë‚˜. ... í•­ëª© (ë˜ëŠ” ê²½ê³ í‘œì§€)
    KEY_COMP_START = "3.êµ¬ì„±ì„±ë¶„" # ë‹¤ìŒ ì±•í„°
    
    # Pì½”ë“œ ì„¹ì…˜ í‚¤ì›Œë“œ
    KEY_PREV = "ì˜ˆë°©"
    KEY_RESP = "ëŒ€ì‘"
    KEY_STOR = "ì €ì¥"
    KEY_DISP = "íê¸°"

    for line in full_text_lines:
        clean_line = line.strip()
        if not clean_line: continue
        
        line_nospace = clean_line.replace(" ", "")
        
        # 1. ìœ í•´ì„± ë¶„ë¥˜ (B20) ì‹œì‘ ê°ì§€
        if KEY_HAZARD_START in line_nospace and "ê°€." in line_nospace:
            mode = 'hazard_cls'
            continue # ì œëª© ì¤„ì€ í¬í•¨ ì•ˆ í•¨
        
        # 2. ì˜ˆë°©ì¡°ì¹˜ë¬¸êµ¬ (ê²½ê³ í‘œì§€ í•­ëª©) ì‹œì‘ ê°ì§€ -> B20 ì¢…ë£Œ
        if KEY_LABEL_START in line_nospace:
            mode = 'label_elements'
            p_section = None # ì•„ì§ ì†Œì œëª© ì•ˆ ë‚˜ì˜´
            continue
        
        # 3. ì„¹ì…˜ 3 ì‹œì‘ -> ì¢…ë£Œ
        if KEY_COMP_START in line_nospace:
            break

        # --- ëª¨ë“œë³„ ë™ì‘ ---
        
        # [A] ìœ í•´ì„± ë¶„ë¥˜ ë‚´ìš© ìˆ˜ì§‘
        if mode == 'hazard_cls':
            # ë‚´ìš©ì— Hì½”ë“œ ë“±ì´ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìŒ
            extracted_data["hazard_classification"].append(clean_line)
            # ì—¬ê¸°ì„œ Hì½”ë“œ ì¶”ì¶œ
            h_found = re.findall(r"H\d{3}", clean_line)
            extracted_data["h_codes"].extend(h_found)

        # [B] ì˜ˆë°©ì¡°ì¹˜ë¬¸êµ¬ ë‚´ìš© ìˆ˜ì§‘ (Pì½”ë“œ ì„¹ì…˜ ê°ì§€)
        elif mode == 'label_elements':
            # ì†Œì œëª© ê°ì§€ (ì¤„ì˜ ì‹œì‘ ë¶€ë¶„ì´ í‚¤ì›Œë“œì¼ ë•Œ)
            # ì£¼ì˜: "ì˜ˆë°©ì¡°ì¹˜"ë¼ëŠ” ë‹¨ì–´ê°€ ë¬¸ì¥ì— ë“¤ì–´ê°ˆ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ ì£¼ì˜
            
            # ì„¹ì…˜ ì „í™˜ ë¡œì§ (ìš°ì„ ìˆœìœ„: íê¸° > ì €ì¥ > ëŒ€ì‘ > ì˜ˆë°©)
            if clean_line.startswith(KEY_DISP):
                p_section = 'disposal'
            elif clean_line.startswith(KEY_STOR):
                p_section = 'storage'
            elif clean_line.startswith(KEY_RESP):
                p_section = 'response'
            elif clean_line.startswith(KEY_PREV):
                p_section = 'prevention'
            
            # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ë‹´ê¸° (ì œëª© ì¤„ í¬í•¨ ì—¬ë¶€ëŠ” ë‚´ìš©ì— ë”°ë¼ ë‹¤ë¥´ë‚˜, ì½”ë“œëŠ” ë³´í†µ ì œëª© ì¤„ì— ì—†ìŒ)
            if p_section:
                # Pì½”ë“œ ì¶”ì¶œ (P300+P310 ê°™ì€ ë³µí•© ì½”ë“œ ì§€ì›)
                # ì •ê·œì‹: Pìˆ«ì3ê°œ + (í”ŒëŸ¬ìŠ¤ + Pìˆ«ì3ê°œ)ê°€ 0ë²ˆ ì´ìƒ ë°˜ë³µ
                p_codes = re.findall(r"P\d{3}(?:\s*\+\s*P\d{3})*", clean_line)
                if p_codes:
                    extracted_data[p_section].extend(p_codes)

    return extracted_data

# 2. íŒŒì¼ ì—…ë¡œë“œ
with st.expander("ğŸ“‚ í•„ìˆ˜ íŒŒì¼ ì—…ë¡œë“œ", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        master_data_file = st.file_uploader("1. ì¤‘ì•™ ë°ì´í„° (master_data.xlsx)", type="xlsx")
        loaded_refs, folder_exists = get_reference_images()
        if folder_exists and loaded_refs:
            st.success(f"âœ… ê¸°ì¤€ ê·¸ë¦¼ {len(loaded_refs)}ê°œ ë¡œë“œë¨")
        elif not folder_exists:
            st.warning("âš ï¸ 'reference_imgs' í´ë” í•„ìš”")

    with col2:
        template_file = st.file_uploader("2. ì–‘ì‹ íŒŒì¼ (í†µí•© ì–‘ì‹ GHS MSDS(K).xlsx)", type="xlsx")

product_name_input = st.text_input("ì œí’ˆëª… ì…ë ¥ (B7, B10)")
option = st.selectbox("ì ìš©í•  ì–‘ì‹", ("CFF(K)", "CFF(E)", "HP(K)", "HP(E)"))
st.write("") 

# 3. ë©”ì¸ ë¡œì§
col_left, col_center, col_right = st.columns([4, 2, 4])

if 'converted_files' not in st.session_state:
    st.session_state['converted_files'] = []
    st.session_state['download_data'] = {}

with col_left:
    st.subheader("3. ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("ì›ë³¸ ë°ì´í„°(PDF)", type=["pdf"], accept_multiple_files=True)

with col_center:
    st.write("") ; st.write("") ; st.write("")
    
    if st.button("â–¶ ë³€í™˜ ì‹œì‘", use_container_width=True):
        if uploaded_files and master_data_file and template_file:
            with st.spinner("PDF ì •ë°€ ë¶„ì„ ì¤‘..."):
                
                new_files = []
                new_download_data = {}
                
                # ì¤‘ì•™ ë°ì´í„° ë¡œë“œ (ë§¤í•‘ìš©)
                try: 
                    df_master = pd.read_excel(master_data_file, sheet_name=0)
                    code_map = {}
                    for idx, row in df_master.iterrows():
                        # ê³µë°± ì œê±° ë° ë¬¸ìì—´ ë³€í™˜
                        code_val = str(row.iloc[0]).replace(" ", "").strip()
                        desc_val = str(row.iloc[1]).strip()
                        code_map[code_val] = desc_val
                except: 
                    df_master = pd.DataFrame()
                    code_map = {}

                for uploaded_file in uploaded_files:
                    if option == "CFF(K)":
                        try:
                            # 1. PDF ë¡œë“œ ë° íŒŒì‹±
                            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                            parsed_data = parse_pdf_ghs_section(doc)
                            
                            # 2. ì–‘ì‹ íŒŒì¼ ì¤€ë¹„
                            template_file.seek(0)
                            dest_wb = load_workbook(io.BytesIO(template_file.read()))
                            dest_ws = dest_wb.active

                            # [ë°ì´í„° ë™ê¸°í™” & ìˆ˜ì‹ ìˆ˜ì •]
                            target_sheet = 'ìœ„í—˜ ì•ˆì „ë¬¸êµ¬'
                            if target_sheet in dest_wb.sheetnames: del dest_wb[target_sheet]
                            data_ws = dest_wb.create_sheet(target_sheet)
                            for r in dataframe_to_rows(df_master, index=False, header=True): data_ws.append(r)

                            for row in dest_ws.iter_rows():
                                for cell in row:
                                    if cell.data_type == 'f':
                                        f_str = str(cell.value)
                                        if "ingredients CAS and EC í†µí•©.xlsx]" in f_str:
                                            new_f = re.sub(r"'?[a-zA-Z]:\\[^']*\['?[^']*'?.xlsx\]", "'", f_str)
                                            new_f = re.sub(r"\[[^\]]*\.xlsx\]", "", new_f)
                                            cell.value = new_f

                            dest_ws['B7'] = product_name_input
                            dest_ws['B10'] = product_name_input
                            
                            # ---------------------------------------------------
                            # [ë°ì´í„° ì…ë ¥] íŒŒì‹±ëœ ë°ì´í„° ë„£ê¸°
                            # ---------------------------------------------------
                            
                            # [A] ìœ í•´ì„± ë¶„ë¥˜ (B20)
                            # ë¦¬ìŠ¤íŠ¸ë¥¼ ì¤„ë°”ê¿ˆ ë¬¸ìë¡œ í•©ì¹¨
                            b20_text = "\n".join(parsed_data["hazard_classification"])
                            dest_ws['B20'] = b20_text
                            dest_ws['B20'].alignment = Alignment(wrap_text=True, vertical='center', horizontal='left')

                            # [B] Hì½”ë“œ (B25 ~ B30)
                            # ì¤‘ë³µ ì œê±° ë° ìˆœì„œ ìœ ì§€
                            unique_h = sorted(list(set(parsed_data["h_codes"])))
                            
                            curr = 25
                            for code in unique_h:
                                if curr > 30: break
                                clean_code = code.replace(" ", "").strip()
                                dest_ws.cell(row=curr, column=2).value = clean_code
                                dest_ws.cell(row=curr, column=4).value = code_map.get(clean_code, "")
                                curr += 1
                            
                            # ë¹ˆ í–‰ ìˆ¨ê¸°ê¸°
                            for r in range(25, 31):
                                if not dest_ws.cell(row=r, column=2).value:
                                    dest_ws.row_dimensions[r].hidden = True
                                else:
                                    dest_ws.row_dimensions[r].hidden = False

                            # [C] Pì½”ë“œ ì…ë ¥ í•¨ìˆ˜
                            def fill_section_codes(p_code_list, start_row, end_row):
                                # ì¤‘ë³µ ì œê±°
                                unique_p = []
                                for p in p_code_list:
                                    # ê³µë°± ì •ê·œí™” (P300 + P310 -> P300+P310)
                                    norm_p = p.replace(" ", "")
                                    if norm_p not in unique_p: unique_p.append(norm_p)
                                
                                # ìˆ¨ê¹€ ì·¨ì†Œ
                                for r in range(start_row, end_row + 1):
                                    dest_ws.row_dimensions[r].hidden = False
                                
                                curr = start_row
                                for p_code in unique_p:
                                    if curr > end_row: break
                                    dest_ws.cell(row=curr, column=2).value = p_code
                                    dest_ws.cell(row=curr, column=4).value = code_map.get(p_code, "") # ë§¤ì¹­
                                    curr += 1
                                
                                # ë¹ˆ í–‰ ìˆ¨ê¸°ê¸°
                                for r in range(start_row, end_row + 1):
                                    if not dest_ws.cell(row=r, column=2).value:
                                        dest_ws.row_dimensions[r].hidden = True

                            # ì„¹ì…˜ë³„ ì ìš©
                            fill_section_codes(parsed_data["prevention"], 32, 41)
                            fill_section_codes(parsed_data["response"], 42, 49)
                            fill_section_codes(parsed_data["storage"], 50, 52)
                            fill_section_codes(parsed_data["disposal"], 53, 53)

                            # ---------------------------------------------------
                            # [ê¸°ì¡´ ê¸°ëŠ¥] ì´ë¯¸ì§€ ì •ë ¬ (ë¡œì§ ìœ ì§€)
                            # ---------------------------------------------------
                            target_anchor_row = 22
                            if hasattr(dest_ws, '_images'):
                                preserved_imgs = []
                                for img in dest_ws._images:
                                    try:
                                        if not (target_anchor_row - 2 <= img.anchor._from.row <= target_anchor_row + 2):
                                            preserved_imgs.append(img)
                                    except: preserved_imgs.append(img)
                                dest_ws._images = preserved_imgs
                            
                            collected_pil_images = []
                            for page_index in range(len(doc)):
                                image_list = doc.get_page_images(page_index)
                                for img_info in image_list:
                                    xref = img_info[0]
                                    base_image = doc.extract_image(xref)
                                    image_bytes = base_image["image"]
                                    try:
                                        pil_img = PILImage.open(io.BytesIO(image_bytes))
                                        matched_name = None
                                        if loaded_refs:
                                            matched_name = find_best_match_name(pil_img, loaded_refs)
                                        if matched_name:
                                            sort_key = extract_number(matched_name)
                                            collected_pil_images.append((sort_key, pil_img))
                                    except: continue
                            
                            unique_images = {}
                            for key, img in collected_pil_images:
                                if key not in unique_images: unique_images[key] = img
                            
                            final_images = sorted(unique_images.items(), key=lambda x: x[0])
                            sorted_imgs = [item[1] for item in final_images]
                            
                            if sorted_imgs:
                                unit_size = 67 
                                icon_size = 60 
                                padding_top = 4 
                                padding_left = (unit_size - icon_size) // 2 
                                total_width = unit_size * len(sorted_imgs)
                                total_height = unit_size 
                                merged_img = PILImage.new('RGBA', (total_width, total_height), (255, 255, 255, 0))
                                for idx, p_img in enumerate(sorted_imgs):
                                    p_img_resized = p_img.resize((icon_size, icon_size), PILImage.LANCZOS)
                                    merged_img.paste(p_img_resized, ((idx * unit_size) + padding_left, padding_top))
                                
                                img_byte_arr = io.BytesIO()
                                merged_img.save(img_byte_arr, format='PNG') 
                                img_byte_arr.seek(0)
                                dest_ws.add_image(XLImage(img_byte_arr), 'B23')

                            output = io.BytesIO()
                            dest_wb.save(output)
                            output.seek(0)
                            
                            final_name = f"{product_name_input} GHS MSDS(K).xlsx"
                            if final_name in new_download_data:
                                final_name = f"{product_name_input}_{uploaded_file.name.split('.')[0]} GHS MSDS(K).xlsx"
                            
                            new_download_data[final_name] = output.getvalue()
                            new_files.append(final_name)
                            
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ({uploaded_file.name}): {e}")

                st.session_state['converted_files'] = new_files
                st.session_state['download_data'] = new_download_data
                
                del df_master
                if 'doc' in locals(): doc.close()
                if 'dest_wb' in locals(): del dest_wb
                if 'output' in locals(): del output
                gc.collect()

                if new_files:
                    st.success("ì™„ë£Œ! PDF ë¶„ì„ ë° ë³€í™˜ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
        else:
            st.error("ëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

with col_right:
    st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    if st.session_state['converted_files']:
        for i, fname in enumerate(st.session_state['converted_files']):
            c1, c2 = st.columns([3, 1])
            with c1: st.text(f"ğŸ“„ {fname}")
            with c2:
                st.download_button(
                    label="ë°›ê¸°", 
                    data=st.session_state['download_data'][fname], 
                    file_name=fname, 
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=i
                )
