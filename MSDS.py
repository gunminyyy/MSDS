import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Alignment, Font, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.cell.cell import MergedCell
from copy import copy # [í•„ìˆ˜] ìŠ¤íƒ€ì¼ ë³µì‚¬ë¥¼ ìœ„í•´ í•„ìš”
from PIL import Image as PILImage
import io
import re
import os
import fitz  # PyMuPDF
import numpy as np

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MSDS ìŠ¤ë§ˆíŠ¸ ë³€í™˜ê¸°", layout="wide")
st.title("MSDS ì–‘ì‹ ë³€í™˜ê¸° (í–‰ ë³µì œ & ìŠ¤íƒ€ì¼ ì™„ë²½ ì´ì‹)")
st.markdown("---")

# --------------------------------------------------------------------------
# [ìŠ¤íƒ€ì¼ ì •ì˜] êµ´ë¦¼ 8pt, ì™¼ìª½ ì •ë ¬
# --------------------------------------------------------------------------
FONT_STYLE = Font(name='êµ´ë¦¼', size=8)
ALIGN_LEFT = Alignment(horizontal='left', vertical='center', wrap_text=True)
BORDER_THIN = Border(left=Side(style='thin'), right=Side(style='thin'), top=Side(style='thin'), bottom=Side(style='thin'))

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ì´ë¯¸ì§€ ì²˜ë¦¬
# --------------------------------------------------------------------------
def normalize_image(pil_img):
    try:
        if pil_img.mode in ('RGBA', 'LA') or (pil_img.mode == 'P' and 'transparency' in pil_img.info):
            background = PILImage.new('RGB', pil_img.size, (255, 255, 255))
            if pil_img.mode == 'P': pil_img = pil_img.convert('RGBA')
            background.paste(pil_img, mask=pil_img.split()[3])
            pil_img = background
        else:
            pil_img = pil_img.convert('RGB')
        return pil_img.resize((32, 32)).convert('L')
    except:
        return pil_img.resize((32, 32)).convert('L')

def get_reference_images():
    img_folder = "reference_imgs"
    if not os.path.exists(img_folder): return {}, False
    try:
        ref_images = {}
        file_list = sorted(os.listdir(img_folder)) 
        for fname in file_list:
            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.tif', '.tiff')):
                full_path = os.path.join(img_folder, fname)
                try:
                    pil_img = PILImage.open(full_path)
                    ref_images[fname] = pil_img
                except: continue
        return ref_images, True
    except: return {}, False

def find_best_match_name(src_img, ref_images):
    best_score = float('inf')
    best_name = None
    try:
        src_norm = normalize_image(src_img)
        src_arr = np.array(src_norm, dtype='int16')
        for name, ref_img in ref_images.items():
            ref_norm = normalize_image(ref_img)
            ref_arr = np.array(ref_norm, dtype='int16')
            diff = np.mean(np.abs(src_arr - ref_arr))
            if diff < best_score:
                best_score = diff
                best_name = name
        if best_score < 65: return best_name
        else: return None
    except: return None

def extract_number(filename):
    nums = re.findall(r'\d+', filename)
    return int(nums[0]) if nums else 999

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] PDF íŒŒì‹±
# --------------------------------------------------------------------------
def parse_pdf_ghs_logic(doc):
    clean_lines = []
    NOISE_KEYWORDS = [
        "ë¬¼ì§ˆì•ˆì „ë³´ê±´ìë£Œ", "MSDS", "Material Safety Data Sheet",
        "Corea flavors", "ì£¼ì‹íšŒì‚¬ ê³ ë ¤", "HAIR CARE", "Ver.", "ë°œí–‰ì¼", "ê°œì •ì¼",
        "ì œ í’ˆ ëª…", "GHS", "í˜ì´ì§€", "PAGE", "---"
    ]

    for page in doc:
        blocks = page.get_text("blocks", sort=True)
        for b in blocks:
            text = b[4]
            lines = text.split('\n')
            for line in lines:
                line_str = line.strip()
                if not line_str: continue
                is_noise = False
                for kw in NOISE_KEYWORDS:
                    if kw.replace(" ", "") in line_str.replace(" ", ""):
                        is_noise = True; break
                if not is_noise: clean_lines.append(line_str)

    result = {
        "hazard_cls": [], "signal_word": "", "h_codes": [],
        "p_prev": [], "p_resp": [], "p_stor": [], "p_disp": []
    }

    ZONE_NONE = 0; ZONE_HAZARD_CLS = 1; ZONE_LABEL_INFO = 2
    current_zone = ZONE_NONE
    SUB_NONE=0; SUB_PREV=1; SUB_RESP=2; SUB_STOR=3; SUB_DISP=4
    current_sub = SUB_NONE
    
    regex_code = re.compile(r"([HP]\d{3}(?:\s*\+\s*[HP]\d{3})*)")
    BLACKLIST_HAZARD = ["ê³µê¸‰ìì •ë³´", "íšŒì‚¬ëª…", "ì£¼ì†Œ", "ê¸´ê¸‰ì „í™”ë²ˆí˜¸", "ê¶Œê³ ìš©ë„", "ì‚¬ìš©ìƒì˜ì œí•œ"]

    for line in clean_lines:
        line_ns = line.replace(" ", "")
        
        if "ê°€.ìœ í•´ì„±" in line_ns and "ë¶„ë¥˜" in line_ns:
            current_zone = ZONE_HAZARD_CLS; continue
        if "ë‚˜.ì˜ˆë°©ì¡°ì¹˜" in line_ns:
            current_zone = ZONE_LABEL_INFO; current_sub = SUB_NONE; continue
        if "3.êµ¬ì„±ì„±ë¶„" in line_ns or "ë‹¤.ê¸°íƒ€" in line_ns:
            current_zone = ZONE_NONE; break

        if current_zone == ZONE_HAZARD_CLS:
            is_bad = False
            for bl in BLACKLIST_HAZARD:
                if bl in line_ns: is_bad = True; break
            if not is_bad:
                result["hazard_cls"].append(line)
                codes = regex_code.findall(line)
                for c in codes:
                    if c.startswith("H"): result["h_codes"].append(c)

        elif current_zone == ZONE_LABEL_INFO:
            if "ì‹ í˜¸ì–´" in line_ns:
                val = line.replace("ì‹ í˜¸ì–´", "").replace(":", "").strip()
                if val: result["signal_word"] = val
            
            if line_ns.startswith("ì˜ˆë°©") and len(line_ns) < 15: current_sub = SUB_PREV
            elif line_ns.startswith("ëŒ€ì‘") and len(line_ns) < 15: current_sub = SUB_RESP
            elif line_ns.startswith("ì €ì¥") and len(line_ns) < 15: current_sub = SUB_STOR
            elif line_ns.startswith("íê¸°") and len(line_ns) < 15: current_sub = SUB_DISP

            codes = regex_code.findall(line)
            for c in codes:
                if c.startswith("H"): result["h_codes"].append(c)
                elif c.startswith("P"):
                    if current_sub == SUB_PREV: result["p_prev"].append(c)
                    elif current_sub == SUB_RESP: result["p_resp"].append(c)
                    elif current_sub == SUB_STOR: result["p_stor"].append(c)
                    elif current_sub == SUB_DISP: result["p_disp"].append(c)

    return result

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ì¤‘ì•™ ë°ì´í„° ë§¤í•‘ (ë¶„í•  ê²€ìƒ‰)
# --------------------------------------------------------------------------
def get_description_smart(code, code_map):
    clean_code = code.replace(" ", "").upper().strip()
    if clean_code in code_map:
        return code_map[clean_code]
    if "+" in clean_code:
        parts = clean_code.split("+")
        found_texts = []
        for p in parts:
            if p in code_map:
                found_texts.append(code_map[p])
        if found_texts:
            return " ".join(found_texts)
    return ""

# --------------------------------------------------------------------------
# [í•µì‹¬] í–‰ ìŠ¤íƒ€ì¼ ë³µì‚¬ í•¨ìˆ˜ (í–‰ ì „ì²´ ì„œì‹ ë³µì œ)
# --------------------------------------------------------------------------
def copy_row_style(ws, source_row_idx, target_row_idx):
    """
    source_row_idxì˜ ëª¨ë“  ì…€ ìŠ¤íƒ€ì¼ì„ target_row_idxë¡œ ë³µì‚¬í•©ë‹ˆë‹¤.
    """
    # ë†’ì´ ë³µì‚¬
    ws.row_dimensions[target_row_idx].height = ws.row_dimensions[source_row_idx].height
    
    # ì…€ ë‹¨ìœ„ ìŠ¤íƒ€ì¼ ë³µì‚¬ (Aì—´ë¶€í„° Kì—´ ì •ë„ê¹Œì§€)
    for col in range(1, 15): 
        source_cell = ws.cell(row=source_row_idx, column=col)
        target_cell = ws.cell(row=target_row_idx, column=col)
        
        # ìŠ¤íƒ€ì¼ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë³µì‚¬
        if source_cell.has_style:
            # ì£¼ì˜: _styleì„ ì§ì ‘ ë³µì‚¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•¨
            try:
                target_cell._style = copy(source_cell._style)
            except:
                # _style ë³µì‚¬ê°€ ì•ˆë˜ë©´ ìˆ˜ë™ ì†ì„± ë³µì‚¬ (ì•ˆì „ì¥ì¹˜)
                target_cell.font = copy(source_cell.font)
                target_cell.border = copy(source_cell.border)
                target_cell.fill = copy(source_cell.fill)
                target_cell.number_format = copy(source_cell.number_format)
                target_cell.protection = copy(source_cell.protection)
                target_cell.alignment = copy(source_cell.alignment)

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ì•ˆì „ ì“°ê¸° (ì„œì‹ì€ ê±´ë“œë¦¬ì§€ ì•Šê³  ê°’ë§Œ ë„£ìŒ)
# --------------------------------------------------------------------------
def safe_write_value_only(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    # ë³‘í•©ëœ ì…€ì´ë©´ í•´ì œ (ë°ì´í„° ì…ë ¥ í•„ìˆ˜)
    if isinstance(cell, MergedCell):
        for rng in ws.merged_cells.ranges:
            if cell.coordinate in rng:
                ws.unmerge_cells(str(rng))
                break
        cell = ws.cell(row=row, column=col) # ê°±ì‹ 

    # ê°’ ì…ë ¥
    cell.value = value
    
    # í°íŠ¸/ì •ë ¬ ê°•ì œ ì ìš© (ì‚¬ìš©ì ìš”ì²­: êµ´ë¦¼ 8pt, ì™¼ìª½)
    cell.font = FONT_STYLE
    cell.alignment = ALIGN_LEFT
    cell.border = BORDER_THIN

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ìŠ¤ë§ˆíŠ¸ í–‰ ê´€ë¦¬ (í–‰ ë³µì œ ë°©ì‹)
# --------------------------------------------------------------------------
def write_ghs_data_clone_row(ws, parsed_data, code_map):
    
    anchors = {"H": -1, "PREV": -1, "RESP": -1, "STOR": -1, "DISP": -1}
    for r in range(1, 150):
        val = str(ws.cell(row=r, column=2).value).replace(" ", "")
        if "ìœ í•´Â·ìœ„í—˜ë¬¸êµ¬" in val: anchors["H"] = r
        elif val == "ì˜ˆë°©": anchors["PREV"] = r
        elif val == "ëŒ€ì‘": anchors["RESP"] = r
        elif val == "ì €ì¥": anchors["STOR"] = r
        elif val == "íê¸°": anchors["DISP"] = r
    
    if anchors["H"] == -1: anchors["H"] = 24
    if anchors["PREV"] == -1: anchors["PREV"] = 31
    if anchors["RESP"] == -1: anchors["RESP"] = 41
    if anchors["STOR"] == -1: anchors["STOR"] = 49
    if anchors["DISP"] == -1: anchors["DISP"] = 52

    offset = 0 
    
    sections = [
        ("H", parsed_data["h_codes"], "PREV"),
        ("PREV", parsed_data["p_prev"], "RESP"),
        ("RESP", parsed_data["p_resp"], "STOR"),
        ("STOR", parsed_data["p_stor"], "DISP"),
        ("DISP", parsed_data["p_disp"], "END")
    ]
    
    for section_name, codes, next_section_name in sections:
        
        # ë°ì´í„° ì‹œì‘ í–‰ (í—¤ë” ë°”ë¡œ ë‹¤ìŒ)
        start_row = anchors[section_name] + offset + 1
        
        # ë ì§€ì  ê³„ì‚°
        if next_section_name == "END":
            next_header_row = start_row + 1
        else:
            next_header_row = anchors[next_section_name] + offset
            
        capacity = next_header_row - start_row
        
        # ì½”ë“œ ì •ê·œí™”
        unique_codes = []
        for c in codes:
            clean = c.replace(" ", "").upper().strip()
            if clean not in unique_codes: unique_codes.append(clean)
        
        needed = len(unique_codes)
        
        # [í•µì‹¬] í–‰ ë¶€ì¡± ì‹œ -> "í–‰ ì‚½ì…" í›„ "ì²« ì¤„ ì„œì‹ ë³µì‚¬"
        if needed > capacity:
            rows_to_add = needed - capacity
            insert_pos = next_header_row 
            
            # 1. í–‰ ì‚½ì… (ê¹¡í†µ í–‰ ìƒì„±)
            ws.insert_rows(insert_pos, amount=rows_to_add)
            
            # 2. ì„œì‹ ë³µì‚¬ (Start Rowì˜ ìŠ¤íƒ€ì¼ì„ ìƒˆë¡œ ìƒê¸´ í–‰ë“¤ì— ë®ì–´ì”Œì›€)
            # Start RowëŠ” í•´ë‹¹ ì„¹ì…˜ì˜ ì²« ë²ˆì§¸ ì¤„ì´ë¯€ë¡œ, ì˜¬ë°”ë¥¸ ì–‘ì‹ì„ ê°€ì§€ê³  ìˆìŒ
            template_row = start_row 
            
            for r_idx in range(rows_to_add):
                target_r = insert_pos + r_idx
                copy_row_style(ws, template_row, target_r)
            
            offset += rows_to_add
            capacity += rows_to_add
        
        # ë°ì´í„° ì“°ê¸°
        curr = start_row
        for i, code in enumerate(unique_codes):
            ws.row_dimensions[curr].hidden = False
            
            # ê°’ ì…ë ¥ (í•¨ìˆ˜ ë‚´ì—ì„œ êµ´ë¦¼ 8pt, ì™¼ìª½ ì •ë ¬ ì ìš©)
            safe_write_value_only(ws, curr, 2, code) # Bì—´
            
            desc = get_description_smart(code, code_map)
            safe_write_value_only(ws, curr, 4, desc) # Dì—´
            
            curr += 1
            
        # ë‚¨ì€ ë¹ˆ ê³µê°„ ì •ë¦¬
        limit_row = start_row + capacity
        for r in range(curr, limit_row):
            safe_write_value_only(ws, r, 2, "")
            safe_write_value_only(ws, r, 4, "")
            ws.row_dimensions[r].hidden = True

# 2. íŒŒì¼ ì—…ë¡œë“œ
with st.expander("ğŸ“‚ í•„ìˆ˜ íŒŒì¼ ì—…ë¡œë“œ", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        master_data_file = st.file_uploader("1. ì¤‘ì•™ ë°ì´í„° (master_data.xlsx)", type="xlsx")
        loaded_refs, folder_exists = get_reference_images()
        if folder_exists and loaded_refs:
            st.success(f"âœ… ê¸°ì¤€ ê·¸ë¦¼ {len(loaded_refs)}ê°œ ë¡œë“œë¨")
        elif not folder_exists:
            st.warning("âš ï¸ 'reference_imgs' í´ë” í•„ìš”")

    with col2:
        template_file = st.file_uploader("2. ì–‘ì‹ íŒŒì¼ (í†µí•© ì–‘ì‹ GHS MSDS(K).xlsx)", type="xlsx")

product_name_input = st.text_input("ì œí’ˆëª… ì…ë ¥ (B7, B10)")
option = st.selectbox("ì ìš©í•  ì–‘ì‹", ("CFF(K)", "CFF(E)", "HP(K)", "HP(E)"))
st.write("") 

# 3. ë©”ì¸ ë¡œì§
col_left, col_center, col_right = st.columns([4, 2, 4])

if 'converted_files' not in st.session_state:
    st.session_state['converted_files'] = []
    st.session_state['download_data'] = {}

with col_left:
    st.subheader("3. ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("ì›ë³¸ ë°ì´í„°(PDF)", type=["pdf"], accept_multiple_files=True)

with col_center:
    st.write("") ; st.write("") ; st.write("")
    
    if st.button("â–¶ ë³€í™˜ ì‹œì‘", use_container_width=True):
        if uploaded_files and master_data_file and template_file:
            with st.spinner("í–‰ ë³µì œ ë° ì–‘ì‹ ìµœì í™” ì¤‘..."):
                
                new_files = []
                new_download_data = {}
                
                try: 
                    df_master = pd.read_excel(master_data_file, sheet_name=0)
                    df_master.columns = [str(c).replace(" ", "").upper() for c in df_master.columns]
                    col_code = 'CODE' if 'CODE' in df_master.columns else df_master.columns[0]
                    col_kor = 'K' if 'K' in df_master.columns else (df_master.columns[1] if len(df_master.columns)>1 else None)
                    
                    code_map = {}
                    if col_kor:
                        for idx, row in df_master.iterrows():
                            if pd.notna(row[col_code]):
                                k = str(row[col_code]).replace(" ", "").upper().strip()
                                v = str(row[col_kor]).strip() if pd.notna(row[col_kor]) else ""
                                code_map[k] = v
                except Exception as e:
                    st.error(f"ì¤‘ì•™ ë°ì´í„° ì˜¤ë¥˜: {e}")
                    code_map = {}

                for uploaded_file in uploaded_files:
                    if option == "CFF(K)":
                        try:
                            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                            parsed_data = parse_pdf_ghs_logic(doc)
                            
                            template_file.seek(0)
                            dest_wb = load_workbook(io.BytesIO(template_file.read()))
                            dest_ws = dest_wb.active

                            target_sheet = 'ìœ„í—˜ ì•ˆì „ë¬¸êµ¬'
                            if target_sheet in dest_wb.sheetnames: del dest_wb[target_sheet]
                            data_ws = dest_wb.create_sheet(target_sheet)
                            for r in dataframe_to_rows(df_master, index=False, header=True): data_ws.append(r)

                            # ìˆ˜ì‹ ì²­ì†Œ
                            for row in dest_ws.iter_rows():
                                for cell in row:
                                    if isinstance(cell, MergedCell): continue
                                    if cell.data_type == 'f' and "ingredients" in str(cell.value):
                                        cell.value = ""

                            # ê¸°ë³¸ ë°ì´í„°
                            safe_write_value_only(dest_ws, 7, 2, product_name_input)
                            safe_write_value_only(dest_ws, 10, 2, product_name_input)
                            
                            if parsed_data["hazard_cls"]:
                                b20_text = "\n".join(parsed_data["hazard_cls"])
                                safe_write_value_only(dest_ws, 20, 2, b20_text)
                                dest_ws['B20'].alignment = Alignment(wrap_text=True, vertical='center', horizontal='left')

                            if parsed_data["signal_word"]:
                                safe_write_value_only(dest_ws, 24, 2, parsed_data["signal_word"])
                                dest_ws['B24'].alignment = Alignment(horizontal='center', vertical='center')

                            # [í•µì‹¬] í–‰ ë³µì œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì…ë ¥
                            write_ghs_data_clone_row(dest_ws, parsed_data, code_map)

                            # ì´ë¯¸ì§€
                            target_anchor_row = 22
                            if hasattr(dest_ws, '_images'):
                                preserved_imgs = []
                                for img in dest_ws._images:
                                    try:
                                        if not (target_anchor_row - 2 <= img.anchor._from.row <= target_anchor_row + 2):
                                            preserved_imgs.append(img)
                                    except: preserved_imgs.append(img)
                                dest_ws._images = preserved_imgs
                            
                            collected_pil_images = []
                            for page_index in range(len(doc)):
                                image_list = doc.get_page_images(page_index)
                                for img_info in image_list:
                                    xref = img_info[0]
                                    base_image = doc.extract_image(xref)
                                    image_bytes = base_image["image"]
                                    try:
                                        pil_img = PILImage.open(io.BytesIO(image_bytes))
                                        matched_name = None
                                        if loaded_refs:
                                            matched_name = find_best_match_name(pil_img, loaded_refs)
                                        if matched_name:
                                            sort_key = extract_number(matched_name)
                                            collected_pil_images.append((sort_key, pil_img))
                                    except: continue
                            
                            unique_images = {}
                            for key, img in collected_pil_images:
                                if key not in unique_images: unique_images[key] = img
                            
                            final_images = sorted(unique_images.items(), key=lambda x: x[0])
                            sorted_imgs = [item[1] for item in final_images]
                            
                            if sorted_imgs:
                                unit_size = 67 
                                icon_size = 60 
                                padding_top = 4 
                                padding_left = (unit_size - icon_size) // 2 
                                total_width = unit_size * len(sorted_imgs)
                                total_height = unit_size 
                                merged_img = PILImage.new('RGBA', (total_width, total_height), (255, 255, 255, 0))
                                for idx, p_img in enumerate(sorted_imgs):
                                    p_img_resized = p_img.resize((icon_size, icon_size), PILImage.LANCZOS)
                                    merged_img.paste(p_img_resized, ((idx * unit_size) + padding_left, padding_top))
                                
                                img_byte_arr = io.BytesIO()
                                merged_img.save(img_byte_arr, format='PNG') 
                                img_byte_arr.seek(0)
                                dest_ws.add_image(XLImage(img_byte_arr), 'B23')

                            output = io.BytesIO()
                            dest_wb.save(output)
                            output.seek(0)
                            
                            final_name = f"{product_name_input} GHS MSDS(K).xlsx"
                            if final_name in new_download_data:
                                final_name = f"{product_name_input}_{uploaded_file.name.split('.')[0]} GHS MSDS(K).xlsx"
                            
                            new_download_data[final_name] = output.getvalue()
                            new_files.append(final_name)
                            
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ({uploaded_file.name}): {e}")

                st.session_state['converted_files'] = new_files
                st.session_state['download_data'] = new_download_data
                
                del df_master
                if 'doc' in locals(): doc.close()
                if 'dest_wb' in locals(): del dest_wb
                if 'output' in locals(): del output
                gc.collect()

                if new_files:
                    st.success("ì™„ë£Œ! í–‰ ë³µì œ ë° ì„œì‹ ìœ ì§€ê°€ ì™„ë²½í•˜ê²Œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

with col_right:
    st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    if st.session_state['converted_files']:
        for i, fname in enumerate(st.session_state['converted_files']):
            c1, c2 = st.columns([3, 1])
            with c1: st.text(f"ğŸ“„ {fname}")
            with c2:
                st.download_button(
                    label="ë°›ê¸°", 
                    data=st.session_state['download_data'][fname], 
                    file_name=fname, 
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=i
                )
