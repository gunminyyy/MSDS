import streamlit as st
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Alignment, Font, Border, Side
from openpyxl.cell.cell import MergedCell
from openpyxl.drawing.image import Image as XLImage
from PIL import Image as PILImage
import io
import re
import os
import fitz  # PyMuPDF
import numpy as np
import gc
import math

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MSDS ìŠ¤ë§ˆíŠ¸ ë³€í™˜ê¸°", layout="wide")
st.title("MSDS ì–‘ì‹ ë³€í™˜ê¸° (ì¢Œí‘œ ê¸°ë°˜ ë¬¸ì¥ ë³µì› & ì •ë°€ ì •ì œ)")
st.markdown("---")

# --------------------------------------------------------------------------
# [ìŠ¤íƒ€ì¼] êµ´ë¦¼ 8pt
# --------------------------------------------------------------------------
FONT_STYLE = Font(name='êµ´ë¦¼', size=8)
ALIGN_DATA = Alignment(horizontal='left', vertical='center', wrap_text=True)
ALIGN_TITLE = Alignment(horizontal='left', vertical='center', wrap_text=True)
ALIGN_CENTER = Alignment(horizontal='center', vertical='center', wrap_text=True)

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] ì´ë¯¸ì§€ ì²˜ë¦¬
# --------------------------------------------------------------------------
def normalize_image(pil_img):
    try:
        if pil_img.mode in ('RGBA', 'LA') or (pil_img.mode == 'P' and 'transparency' in pil_img.info):
            background = PILImage.new('RGB', pil_img.size, (255, 255, 255))
            if pil_img.mode == 'P': pil_img = pil_img.convert('RGBA')
            background.paste(pil_img, mask=pil_img.split()[3])
            pil_img = background
        else:
            pil_img = pil_img.convert('RGB')
        return pil_img.resize((32, 32)).convert('L')
    except:
        return pil_img.resize((32, 32)).convert('L')

def get_reference_images():
    img_folder = "reference_imgs"
    if not os.path.exists(img_folder): return {}, False
    try:
        ref_images = {}
        file_list = sorted(os.listdir(img_folder)) 
        for fname in file_list:
            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.tif', '.tiff')):
                full_path = os.path.join(img_folder, fname)
                try:
                    pil_img = PILImage.open(full_path)
                    ref_images[fname] = pil_img
                except: continue
        return ref_images, True
    except: return {}, False

def find_best_match_name(src_img, ref_images):
    best_score = float('inf')
    best_name = None
    try:
        src_norm = normalize_image(src_img)
        src_arr = np.array(src_norm, dtype='int16')
        for name, ref_img in ref_images.items():
            ref_norm = normalize_image(ref_img)
            ref_arr = np.array(ref_norm, dtype='int16')
            diff = np.mean(np.abs(src_arr - ref_arr))
            if diff < best_score:
                best_score = diff
                best_name = name
        if best_score < 65: return best_name
        else: return None
    except: return None

def extract_number(filename):
    nums = re.findall(r'\d+', filename)
    return int(nums[0]) if nums else 999

# --------------------------------------------------------------------------
# [í•µì‹¬ í•¨ìˆ˜] PDF ë¼ì¸ ì •ë°€ ì¶”ì¶œ (ì¢Œí‘œ + ë…¸ì´ì¦ˆ ì œê±° + í˜ì´ì§€ í†µí•©)
# --------------------------------------------------------------------------
def get_all_clean_lines_with_coords(doc):
    """
    ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ì¶”ì¶œí•˜ë˜,
    1. í—¤ë”/í‘¸í„° ì˜ì—­(ì¢Œí‘œ) ì œì™¸
    2. ë…¸ì´ì¦ˆ í…ìŠ¤íŠ¸ ì œì™¸
    3. ì „ì—­ Yì¢Œí‘œ(Global Y) ë¶€ì—¬ (í˜ì´ì§€ ë„˜ì–´ê°€ë„ ìˆœì„œ ìœ ì§€)
    """
    all_lines = []
    
    # ë…¸ì´ì¦ˆ íŒ¨í„´
    noise_patterns = [
        r'^\s*\d+\s*/\s*\d+\s*$', r'ë¬¼ì§ˆì•ˆì „ë³´ê±´ìë£Œ', r'Material Safety', 
        r'PAGE', r'Ver\.', r'ë°œí–‰ì¼', r'ì£¼ì‹íšŒì‚¬\s*ê³ ë ¤', r'Cff', 
        r'Corea\s*flavors', r'ì œ\s*í’ˆ\s*ëª…'
    ]
    
    global_y_offset = 0
    
    for page in doc:
        page_h = page.rect.height
        # ìƒí•˜ë‹¨ 50px ì•ˆì „í•˜ê²Œ ì œì™¸ (í—¤ë”/í‘¸í„° ë¬¼ë¦¬ì  ì°¨ë‹¨)
        clip_rect = fitz.Rect(0, 50, page.rect.width, page_h - 50)
        
        # words: (x0, y0, x1, y1, "text", block_no, line_no, word_no)
        words = page.get_text("words", clip=clip_rect)
        words.sort(key=lambda w: (w[1], w[0])) # Yìš°ì„ , Xì°¨ì„  ì •ë ¬
        
        # ì¤„ ë‹¨ìœ„ë¡œ ë¬¶ê¸°
        current_y = -100
        line_buffer = []
        page_lines = [] # item: {'text': str, 'y0': float, 'y1': float}
        
        for w in words:
            text, y0, y1 = w[4], w[1], w[3]
            # ê°™ì€ ì¤„ íŒë‹¨ ê¸°ì¤€: Yì¢Œí‘œ ì°¨ì´ê°€ 3px ì´ë‚´
            if abs(y0 - current_y) > 3:
                if line_buffer:
                    # ì´ì „ ì¤„ ì €ì¥
                    full_text = " ".join([item[0] for item in line_buffer])
                    l_y0 = min([item[1] for item in line_buffer])
                    l_y1 = max([item[2] for item in line_buffer])
                    page_lines.append({'text': full_text, 'y0': l_y0, 'y1': l_y1})
                
                line_buffer = [(text, y0, y1)]
                current_y = y0
            else:
                line_buffer.append((text, y0, y1))
        
        if line_buffer:
            full_text = " ".join([item[0] for item in line_buffer])
            l_y0 = min([item[1] for item in line_buffer])
            l_y1 = max([item[2] for item in line_buffer])
            page_lines.append({'text': full_text, 'y0': l_y0, 'y1': l_y1})
            
        # ë…¸ì´ì¦ˆ í•„í„°ë§ ë° ì „ì—­ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        for line in page_lines:
            is_noise = False
            for pat in noise_patterns:
                if re.search(pat, line['text'], re.IGNORECASE):
                    is_noise = True; break
            
            if not is_noise:
                # ì „ì—­ Yì¢Œí‘œ ê³„ì‚° (í˜ì´ì§€ ë†’ì´ ëˆ„ì )
                line['global_y0'] = line['y0'] + global_y_offset
                line['global_y1'] = line['y1'] + global_y_offset
                all_lines.append(line)
        
        global_y_offset += page_h
        
    return all_lines

# --------------------------------------------------------------------------
# [í•µì‹¬ í•¨ìˆ˜] ì„¹ì…˜ ë°ì´í„° ì¶”ì¶œ ë° ë¬¸ì¥ ë³‘í•© (Gap Logic)
# --------------------------------------------------------------------------
def extract_section_smart(all_lines, start_kw, end_kw):
    # 1. ì‹œì‘/ì¢…ë£Œ ì¸ë±ìŠ¤ ì°¾ê¸°
    start_idx = -1
    end_idx = -1
    
    # Start ì°¾ê¸°
    for i, line in enumerate(all_lines):
        if start_kw in line['text']:
            start_idx = i
            break
    
    if start_idx == -1: return ""
    
    # End ì°¾ê¸° (Start ì´í›„ë¶€í„°)
    # End KeywordëŠ” ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ (ì—¬ëŸ¬ í›„ë³´)
    if isinstance(end_kw, str): end_kw = [end_kw]
    
    for i in range(start_idx + 1, len(all_lines)):
        line_text = all_lines[i]['text']
        for ek in end_kw:
            if ek in line_text:
                end_idx = i
                break
        if end_idx != -1: break
    
    if end_idx == -1: end_idx = len(all_lines) # ëê¹Œì§€
    
    # 2. íƒ€ê²Ÿ ë¼ì¸ë“¤ ê°€ì ¸ì˜¤ê¸° (ì œëª© ì¤„ ì œì™¸)
    target_lines = all_lines[start_idx+1 : end_idx]
    if not target_lines: return ""
    
    # 3. [Tail Cleaning] ì œëª© ì”ì—¬ë¬¼ ì œê±°
    # ì²« 1~2ì¤„ì´ "ì— ë“¤ì–´ê°”ì„ ë•Œ", "ì¡°ì¹˜ì‚¬í•­" ë“±ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì‚­ì œ
    garbage_starts = [
        "ì— ì ‘ì´‰í–ˆì„ ë•Œ", "ì— ë“¤ì–´ê°”ì„ ë•Œ", "ë“¤ì–´ê°”ì„ ë•Œ", "ì ‘ì´‰í–ˆì„ ë•Œ", "í–ˆì„ ë•Œ", 
        "í¡ì…í–ˆì„ ë•Œ", "ë¨¹ì—ˆì„ ë•Œ", "ì£¼ì˜ì‚¬í•­", "ë‚´ìš©ë¬¼", 
        "ì·¨ê¸‰ìš”ë ¹", "ì €ì¥ë°©ë²•", "ë³´í˜¸êµ¬", "ì¡°ì¹˜ì‚¬í•­", "ì œê±° ë°©ë²•",
        "ì†Œí™”ì œ", "ìœ í•´ì„±", "ë¡œë¶€í„° ìƒê¸°ëŠ”", "ì°©ìš©í•  ë³´í˜¸êµ¬", "ë° ì˜ˆë°©ì¡°ì¹˜",
        "ë°©ë²•", "ê²½ê³ í‘œì§€ í•­ëª©", "ê·¸ë¦¼ë¬¸ì"
    ]
    
    cleaned_lines = []
    for line in target_lines:
        txt = line['text'].strip()
        # ì”ì—¬ë¬¼ ì²´í¬
        is_garbage = False
        for gb in garbage_starts:
            # ë¬¸ì¥ ì‹œì‘ì´ ì”ì—¬ë¬¼ì´ê±°ë‚˜, ì”ì—¬ë¬¼ê³¼ ë§¤ìš° ìœ ì‚¬í•˜ë©´
            if txt.startswith(gb) or gb in txt[:10]: 
                # ì´ê²Œ ì§„ì§œ ë‚´ìš©ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ê¸¸ì´ ì²´í¬ (ì§§ìœ¼ë©´ ì”ì—¬ë¬¼ì¼ í™•ë¥  ë†’ìŒ)
                if len(txt) < len(gb) + 5: 
                    is_garbage = True
                # ê¸¸ì–´ë„ ì•ë¶€ë¶„ë§Œ ì˜ë¼ë‚¼ ìˆ˜ ìˆìŒ
                else:
                    # ì•ë¶€ë¶„ë§Œ ë‚ ë¦¼
                    txt = txt.replace(gb, "").strip()
                    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
                    txt = re.sub(r"^[:\.\)\s]+", "", txt)
        
        if not is_garbage and txt:
            line['text'] = txt # í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            cleaned_lines.append(line)
            
    if not cleaned_lines: return ""

    # 4. [Smart Merge] ê°„ê²©(Gap) ê¸°ë°˜ ë¬¸ì¥ ë³‘í•©
    final_text = ""
    if len(cleaned_lines) > 0:
        final_text = cleaned_lines[0]['text']
        
        for i in range(1, len(cleaned_lines)):
            prev = cleaned_lines[i-1]
            curr = cleaned_lines[i]
            
            # ê°„ê²© ê³„ì‚° (í˜„ì¬ì¤„ Top - ì´ì „ì¤„ Bottom)
            gap = curr['global_y0'] - prev['global_y1']
            
            # ê°„ê²© ì„ê³„ê°’ (Threshold)
            # ë³´í†µ ì¤„ê°„ê²©ì€ 2~5px ë‚´ì™¸, ë¬¸ë‹¨ ê°„ê²©ì€ 10px ì´ìƒ
            # ì—¬ê¸°ì„œëŠ” "ë¯¸ì„¸í•œ ë²Œì–´ì§"ì„ ê°ì§€í•´ì•¼ í•˜ë¯€ë¡œ 5px ê¸°ì¤€
            if gap < 6.0: 
                # ê°™ì€ ë¬¸ì¥ (Wrap) -> ê³µë°±ìœ¼ë¡œ ì—°ê²°
                final_text += " " + curr['text']
            else:
                # ë‹¤ë¥¸ ë¬¸ì¥ (List Item) -> ì¤„ë°”ê¿ˆ
                final_text += "\n" + curr['text']
                
    return final_text

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] PDF íŒŒì‹± ë©”ì¸ (ì‹ ê·œ ë¡œì§ í†µí•©)
# --------------------------------------------------------------------------
def parse_pdf_final(doc):
    # 1. ì •ë°€ ë¼ì¸ ì¶”ì¶œ (ì¢Œí‘œ í¬í•¨)
    all_lines = get_all_clean_lines_with_coords(doc)
    
    # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œìš© í’€ í…ìŠ¤íŠ¸ (ë‹¨ìˆœ ê²€ìƒ‰ìš©)
    full_text_simple = "\n".join([l['text'] for l in all_lines])

    result = {
        "hazard_cls": [], "signal_word": "", 
        "h_codes": [], "p_prev": [], "p_resp": [], "p_stor": [], "p_disp": [],
        "composition_data": [],
        "sec4_to_7": {} 
    }

    # --- ê¸°ì¡´ ë¡œì§ (H/Pì½”ë“œ, ì‹ í˜¸ì–´ ë“±) ---
    # ì´ ë¶€ë¶„ì€ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë§¤ì¹­ì´ ë” íš¨ìœ¨ì ì´ë¯€ë¡œ ê¸°ì¡´ clean_lines ë°©ì‹ ì¼ë¶€ ì°¨ìš©
    # í˜¹ì€ all_linesë¥¼ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
    
    state = 0 # NONE
    for line_obj in all_lines:
        line = line_obj['text']
        line_ns = line.replace(" ", "")
        
        if "ê°€.ìœ í•´ì„±" in line_ns and "ë¶„ë¥˜" in line_ns: state = 1; continue
        if "ë‚˜.ì˜ˆë°©ì¡°ì¹˜" in line_ns: state = 0; continue
        
        if state == 1:
            if "ê³µê¸‰ìì •ë³´" in line_ns or "íšŒì‚¬ëª…" in line_ns: continue
            result["hazard_cls"].append(line)
            
        if "ì‹ í˜¸ì–´" in line_ns:
            val = line.replace("ì‹ í˜¸ì–´", "").replace(":", "").strip()
            if val in ["ìœ„í—˜", "ê²½ê³ "]: result["signal_word"] = val
            # ë‹¤ìŒ ì¤„ íƒìƒ‰ì€ all_lines ì¸ë±ìŠ¤ë¡œ ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„  ìƒëµ(ëŒ€ë¶€ë¶„ ê°™ì€ ì¤„/ë‹¤ìŒ ì¤„)

    # H/P ì½”ë“œ (ì „ì—­ ìŠ¤ìº”)
    # 3ë²ˆ ì„¹ì…˜ ì „ê¹Œì§€ë§Œ ìë¥´ê¸°
    limit_y = 999999
    for line in all_lines:
        if "3. êµ¬ì„±ì„±ë¶„" in line['text'] or "3. ì„±ë¶„" in line['text']:
            limit_y = line['global_y0']
            break
            
    target_text_hp = "\n".join([l['text'] for l in all_lines if l['global_y0'] < limit_y])
    regex_code = re.compile(r"([HP]\s?\d{3}(?:\s*\+\s*[HP]\s?\d{3})*)")
    all_matches = regex_code.findall(target_text_hp)
    seen = set()
    if "P321" in target_text_hp and "P321" not in all_matches: all_matches.append("P321")
    for code_raw in all_matches:
        code = code_raw.replace(" ", "").upper()
        if code in seen: continue
        seen.add(code)
        if code.startswith("H"): result["h_codes"].append(code)
        elif code.startswith("P"):
            prefix = code.split("+")[0]
            if prefix.startswith("P2"): result["p_prev"].append(code)
            elif prefix.startswith("P3"): result["p_resp"].append(code)
            elif prefix.startswith("P4"): result["p_stor"].append(code)
            elif prefix.startswith("P5"): result["p_disp"].append(code)

    # --- êµ¬ì„±ì„±ë¶„ (ì¢Œí‘œ ê¸°ë°˜) ---
    # 3ë²ˆ ~ 4ë²ˆ ì‚¬ì´
    regex_cas = re.compile(r'\b(\d{2,7}-\d{2}-\d)\b')
    regex_conc = re.compile(r'\b(\d+)\s*~\s*(\d+)\b')
    
    in_comp = False
    for line in all_lines:
        txt = line['text']
        if "3." in txt and ("ì„±ë¶„" in txt or "Composition" in txt): in_comp = True; continue
        if "4." in txt and ("ì‘ê¸‰" in txt or "First" in txt): in_comp = False; break
        
        if in_comp:
            if re.search(r'\d+\.\d+', txt): continue # ì†Œìˆ˜ì  ì œì™¸
            cas_match = regex_cas.search(txt)
            conc_match = regex_conc.search(txt)
            if cas_match:
                cas_val = cas_match.group(1)
                conc_val = None
                if conc_match:
                    s = conc_match.group(1); e = conc_match.group(2)
                    if s == "1": s = "0"
                    conc_val = f"{s} ~ {e}"
                result["composition_data"].append((cas_val, conc_val))

    # --- [NEW] ì„¹ì…˜ 4 ~ 7 (Gap Logic ì ìš©) ---
    data = {}
    
    # Section 4
    data["B125"] = extract_section_smart(all_lines, "ë‚˜. ëˆˆ", "ë‹¤. í”¼ë¶€")
    data["B126"] = extract_section_smart(all_lines, "ë‹¤. í”¼ë¶€", "ë¼. í¡ì…")
    data["B127"] = extract_section_smart(all_lines, "ë¼. í¡ì…", "ë§ˆ. ë¨¹ì—ˆì„")
    data["B128"] = extract_section_smart(all_lines, "ë§ˆ. ë¨¹ì—ˆì„", "ë°”. ê¸°íƒ€")
    data["B129"] = extract_section_smart(all_lines, "ë°”. ê¸°íƒ€", ["5.", "í­ë°œ"])

    # Section 5
    data["B132"] = extract_section_smart(all_lines, "ê°€. ì ì ˆí•œ", "ë‚˜. í™”í•™ë¬¼ì§ˆ")
    data["B133"] = extract_section_smart(all_lines, "ë‚˜. í™”í•™ë¬¼ì§ˆ", "ë‹¤. í™”ì¬ì§„ì••")
    data["B134"] = extract_section_smart(all_lines, "ë‹¤. í™”ì¬ì§„ì••", ["6.", "ëˆ„ì¶œ"])

    # Section 6
    data["B138"] = extract_section_smart(all_lines, "ê°€. ì¸ì²´ë¥¼", "ë‚˜. í™˜ê²½ì„")
    data["B139"] = extract_section_smart(all_lines, "ë‚˜. í™˜ê²½ì„", "ë‹¤. ì •í™”")
    data["B140"] = extract_section_smart(all_lines, "ë‹¤. ì •í™”", ["7.", "ì·¨ê¸‰"])

    # Section 7
    data["B143"] = extract_section_smart(all_lines, "ê°€. ì•ˆì „ì·¨ê¸‰", "ë‚˜. ì•ˆì „í•œ")
    data["B144"] = extract_section_smart(all_lines, "ë‚˜. ì•ˆì „í•œ", ["8.", "ë…¸ì¶œ"])

    result["sec4_to_7"] = data
    return result

# --------------------------------------------------------------------------
# [í•¨ìˆ˜] í¬ë§·íŒ… & ìœ í‹¸
# --------------------------------------------------------------------------
def get_description_smart(code, code_map):
    clean_code = str(code).replace(" ", "").upper().strip()
    if clean_code in code_map: return code_map[clean_code]
    if "+" in clean_code:
        parts = clean_code.split("+")
        found_texts = []
        for p in parts:
            if p in code_map: found_texts.append(code_map[p])
        if found_texts: return " ".join(found_texts)
    return ""

def safe_write_force(ws, row, col, value, center=False):
    cell = ws.cell(row=row, column=col)
    try: cell.value = value
    except AttributeError:
        try:
            for rng in list(ws.merged_cells.ranges):
                if cell.coordinate in rng:
                    ws.unmerge_cells(str(rng))
                    cell = ws.cell(row=row, column=col)
                    break
            cell.value = value
        except: pass
    if cell.font.name != 'êµ´ë¦¼': cell.font = FONT_STYLE
    if center: cell.alignment = ALIGN_CENTER
    else: cell.alignment = ALIGN_DATA

def calculate_smart_height_basic(text): 
    if not text: return 19.2
    explicit_lines = str(text).count('\n') + 1
    final_lines = max(explicit_lines, 1) # ê¸°ë³¸
    # ê¸´ ì¤„ ëŒ€ëµì  ê³„ì‚°
    for line in str(text).split('\n'):
        if len(line) > 35: final_lines += 1
    
    if final_lines == 1: return 19.2
    elif final_lines == 2: return 23.3
    else: return 33.0

def format_and_calc_height_sec47(text):
    if not text: return "", 19.2
    
    # [ìˆ˜ì •] ë§ˆì¹¨í‘œ ë’¤ ì¤„ë°”ê¿ˆ ë³´ì • (ê¸°ì¡´ ì¤„ë°”ê¿ˆ ìœ ì§€ + ë§ˆì¹¨í‘œ ë’¤ ê°•ì œ)
    # ì´ë¯¸ Gap Logicìœ¼ë¡œ ì¤„ë°”ê¿ˆì€ ì˜ ë˜ì–´ ìˆì„ ê²ƒì„.
    # ì¶”ê°€ë¡œ ë§ˆì¹¨í‘œ ë’¤ì— ê³µë°±ë§Œ ìˆê³  ì¤„ë°”ê¿ˆì´ ì—†ìœ¼ë©´ ì¶”ê°€
    formatted_text = re.sub(r'(?<!\d)\.(?!\d)(?!\n)', '.\n', text)
    
    lines = [line.strip() for line in formatted_text.split('\n') if line.strip()]
    final_text = "\n".join(lines)
    
    # ë†’ì´ ê³„ì‚°
    char_limit = 50 
    total_visual = 0
    for line in lines:
        l_len = 0
        for ch in line: l_len += 2 if 'ê°€' <= ch <= 'í£' else 1
        v = math.ceil(l_len / (char_limit * 2))
        total_visual += max(v, 1)
        
    if total_visual == 0: total_visual = 1
    
    # (ì¤„ ìˆ˜ * 10) + 10
    height = (total_visual * 10) + 10
    return final_text, height

def fill_fixed_range(ws, start_row, end_row, codes, code_map):
    unique_codes = []; seen = set()
    for c in codes:
        clean = c.replace(" ", "").upper().strip()
        if clean not in seen: unique_codes.append(clean); seen.add(clean)
    limit = end_row - start_row + 1
    for i in range(limit):
        current_row = start_row + i
        if i < len(unique_codes):
            code = unique_codes[i]
            desc = get_description_smart(code, code_map)
            ws.row_dimensions[current_row].hidden = False
            final_height = calculate_smart_height_basic(desc)
            ws.row_dimensions[current_row].height = final_height
            safe_write_force(ws, current_row, 2, code, center=False)
            safe_write_force(ws, current_row, 4, desc, center=False)
        else:
            ws.row_dimensions[current_row].hidden = True
            safe_write_force(ws, current_row, 2, "") 
            safe_write_force(ws, current_row, 4, "")

def fill_composition_data(ws, comp_data, cas_to_name_map):
    start_row = 80; end_row = 123; limit = end_row - start_row + 1
    for i in range(limit):
        current_row = start_row + i
        if i < len(comp_data) and comp_data[i][1]:
            cas_no, concentration = comp_data[i]
            clean_cas = cas_no.replace(" ", "").strip()
            chem_name = cas_to_name_map.get(clean_cas, "")
            ws.row_dimensions[current_row].hidden = False
            ws.row_dimensions[current_row].height = 26.7
            safe_write_force(ws, current_row, 1, chem_name, center=True)
            safe_write_force(ws, current_row, 4, cas_no, center=True)
            safe_write_force(ws, current_row, 6, concentration, center=True)
        else:
            ws.row_dimensions[current_row].hidden = True
            safe_write_force(ws, current_row, 1, "")
            safe_write_force(ws, current_row, 4, "")
            safe_write_force(ws, current_row, 6, "")

# 2. íŒŒì¼ ì—…ë¡œë“œ
with st.expander("ğŸ“‚ í•„ìˆ˜ íŒŒì¼ ì—…ë¡œë“œ", expanded=True):
    col1, col2 = st.columns(2)
    with col1:
        master_data_file = st.file_uploader("1. ì¤‘ì•™ ë°ì´í„° (ingredients...xlsx)", type="xlsx")
        loaded_refs, folder_exists = get_reference_images()
        if folder_exists and loaded_refs:
            st.success(f"âœ… ê¸°ì¤€ ê·¸ë¦¼ {len(loaded_refs)}ê°œ ë¡œë“œë¨")
        elif not folder_exists:
            st.warning("âš ï¸ 'reference_imgs' í´ë” í•„ìš”")

    with col2:
        template_file = st.file_uploader("2. ì–‘ì‹ íŒŒì¼ (í†µí•© ì–‘ì‹ GHS MSDS(K).xlsx)", type="xlsx")

product_name_input = st.text_input("ì œí’ˆëª… ì…ë ¥ (B7, B10)")
option = st.selectbox("ì ìš©í•  ì–‘ì‹", ("CFF(K)", "CFF(E)", "HP(K)", "HP(E)"))
st.write("") 

# 3. ë©”ì¸ ë¡œì§
col_left, col_center, col_right = st.columns([4, 2, 4])

if 'converted_files' not in st.session_state:
    st.session_state['converted_files'] = []
    st.session_state['download_data'] = {}

with col_left:
    st.subheader("3. ì›ë³¸ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader("ì›ë³¸ ë°ì´í„°(PDF)", type=["pdf"], accept_multiple_files=True)

with col_center:
    st.write("") ; st.write("") ; st.write("")
    
    if st.button("â–¶ ë³€í™˜ ì‹œì‘", use_container_width=True):
        if uploaded_files and master_data_file and template_file:
            with st.spinner("ì¢Œí‘œ ì •ë°€ ë¶„ì„ ë° ê°„ê²© ê¸°ë°˜ ë¬¸ì¥ ë³µì› ì¤‘..."):
                
                new_files = []
                new_download_data = {}
                
                code_map = {} 
                cas_name_map = {} 
                
                try:
                    xls = pd.ExcelFile(master_data_file)
                    target_sheet = None
                    for sheet in xls.sheet_names:
                        if "ìœ„í—˜" in sheet and "ì•ˆì „" in sheet: target_sheet = sheet; break
                    if not target_sheet:
                         for sheet in xls.sheet_names:
                            df_tmp = pd.read_excel(master_data_file, sheet_name=sheet, nrows=5)
                            if 'CODE' in [str(c).upper() for c in df_tmp.columns]: target_sheet = sheet; break
                    if target_sheet:
                        df_code = pd.read_excel(master_data_file, sheet_name=target_sheet)
                        df_code.columns = [str(c).replace(" ", "").upper() for c in df_code.columns]
                        col_c = 'CODE'; col_k = 'K'
                        for _, row in df_code.iterrows():
                            if pd.notna(row[col_c]):
                                code_map[str(row[col_c]).replace(" ","").upper().strip()] = str(row[col_k]).strip()
                    
                    sheet_kor = None
                    for sheet in xls.sheet_names:
                        if "êµ­ë¬¸" in sheet: sheet_kor = sheet; break
                    if sheet_kor:
                        df_kor = pd.read_excel(master_data_file, sheet_name=sheet_kor)
                        for _, row in df_kor.iterrows():
                            val_cas = row.iloc[0]
                            val_name = row.iloc[1]
                            if pd.notna(val_cas):
                                c = str(val_cas).replace(" ", "").strip()
                                n = str(val_name).strip() if pd.notna(val_name) else ""
                                cas_name_map[c] = n
                except Exception as e:
                    st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")

                for uploaded_file in uploaded_files:
                    if option == "CFF(K)":
                        try:
                            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
                            parsed_data = parse_pdf_final(doc)
                            
                            template_file.seek(0)
                            dest_wb = load_workbook(io.BytesIO(template_file.read()))
                            dest_ws = dest_wb.active

                            # 1. ìˆ˜ì‹ ì²­ì†Œ
                            for row in dest_ws.iter_rows():
                                for cell in row:
                                    if isinstance(cell, MergedCell): continue
                                    if cell.data_type == 'f' and "ingredients" in str(cell.value):
                                        cell.value = ""

                            # 2. ê¸°ë³¸ ì •ë³´
                            safe_write_force(dest_ws, 7, 2, product_name_input, center=True)
                            safe_write_force(dest_ws, 10, 2, product_name_input, center=True)
                            
                            # 3. ìœ í•´ì„± & ì‹ í˜¸ì–´
                            if parsed_data["hazard_cls"]:
                                clean_hazard_text = "\n".join([line for line in parsed_data["hazard_cls"] if line.strip()])
                                safe_write_force(dest_ws, 20, 2, clean_hazard_text, center=False)
                                dest_ws['B20'].alignment = Alignment(wrap_text=True, vertical='center', horizontal='left')

                            signal_final = parsed_data["signal_word"] if parsed_data["signal_word"] else ""
                            safe_write_force(dest_ws, 24, 2, signal_final, center=False) 

                            # 4. H/P ì½”ë“œ
                            fill_fixed_range(dest_ws, 25, 36, parsed_data["h_codes"], code_map)
                            fill_fixed_range(dest_ws, 38, 49, parsed_data["p_prev"], code_map)
                            fill_fixed_range(dest_ws, 50, 63, parsed_data["p_resp"], code_map)
                            fill_fixed_range(dest_ws, 64, 69, parsed_data["p_stor"], code_map)
                            fill_fixed_range(dest_ws, 70, 72, parsed_data["p_disp"], code_map)

                            # 5. êµ¬ì„±ì„±ë¶„
                            fill_composition_data(dest_ws, parsed_data["composition_data"], cas_name_map)

                            # 6. ì„¹ì…˜ 4~7 ë°ì´í„° ì“°ê¸°
                            sec_data = parsed_data["sec4_to_7"]
                            import openpyxl.utils
                            
                            for cell_addr, raw_text in sec_data.items():
                                formatted_txt, row_h = format_and_calc_height_sec47(raw_text)
                                
                                try:
                                    col_str = re.match(r"([A-Z]+)", cell_addr).group(1)
                                    row_num = int(re.search(r"(\d+)", cell_addr).group(1))
                                    col_idx = openpyxl.utils.column_index_from_string(col_str)
                                    
                                    # ì´ˆê¸°í™”
                                    safe_write_force(dest_ws, row_num, col_idx, "")
                                    
                                    if formatted_txt:
                                        # Bì—´ ì“°ê¸°
                                        safe_write_force(dest_ws, row_num, col_idx, formatted_txt, center=False)
                                        dest_ws.row_dimensions[row_num].height = row_h
                                        
                                        # Aì—´ ì •ë ¬ (ì™¼ìª½+ìˆ˜ì§ì¤‘ì•™)
                                        try:
                                            cell_a = dest_ws.cell(row=row_num, column=1)
                                            cell_a.alignment = ALIGN_TITLE
                                        except: pass

                                except Exception as e:
                                    print(f"Cell write error: {cell_addr} - {e}")

                            # 7. ì´ë¯¸ì§€ ì‚½ì…
                            target_anchor_row = 22
                            if hasattr(dest_ws, '_images'):
                                preserved_imgs = []
                                for img in dest_ws._images:
                                    try:
                                        if not (target_anchor_row - 2 <= img.anchor._from.row <= target_anchor_row + 2):
                                            preserved_imgs.append(img)
                                    except: preserved_imgs.append(img)
                                dest_ws._images = preserved_imgs
                            
                            collected_pil_images = []
                            for page_index in range(len(doc)):
                                image_list = doc.get_page_images(page_index)
                                for img_info in image_list:
                                    xref = img_info[0]
                                    base_image = doc.extract_image(xref)
                                    image_bytes = base_image["image"]
                                    try:
                                        pil_img = PILImage.open(io.BytesIO(image_bytes))
                                        matched_name = None
                                        if loaded_refs:
                                            matched_name = find_best_match_name(pil_img, loaded_refs)
                                        if matched_name:
                                            sort_key = extract_number(matched_name)
                                            collected_pil_images.append((sort_key, pil_img))
                                    except: continue
                            
                            unique_images = {}
                            for key, img in collected_pil_images:
                                if key not in unique_images: unique_images[key] = img
                            
                            final_images = sorted(unique_images.items(), key=lambda x: x[0])
                            sorted_imgs = [item[1] for item in final_images]
                            
                            if sorted_imgs:
                                unit_size = 67 
                                icon_size = 60 
                                padding_top = 4 
                                padding_left = (unit_size - icon_size) // 2 
                                total_width = unit_size * len(sorted_imgs)
                                total_height = unit_size 
                                merged_img = PILImage.new('RGBA', (total_width, total_height), (255, 255, 255, 0))
                                for idx, p_img in enumerate(sorted_imgs):
                                    p_img_resized = p_img.resize((icon_size, icon_size), PILImage.LANCZOS)
                                    merged_img.paste(p_img_resized, ((idx * unit_size) + padding_left, padding_top))
                                
                                img_byte_arr = io.BytesIO()
                                merged_img.save(img_byte_arr, format='PNG') 
                                img_byte_arr.seek(0)
                                dest_ws.add_image(XLImage(img_byte_arr), 'B23')

                            output = io.BytesIO()
                            dest_wb.save(output)
                            output.seek(0)
                            
                            final_name = f"{product_name_input} GHS MSDS(K).xlsx"
                            if final_name in new_download_data:
                                final_name = f"{product_name_input}_{uploaded_file.name.split('.')[0]} GHS MSDS(K).xlsx"
                            
                            new_download_data[final_name] = output.getvalue()
                            new_files.append(final_name)
                            
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ({uploaded_file.name}): {e}")

                st.session_state['converted_files'] = new_files
                st.session_state['download_data'] = new_download_data
                
                if 'df_code' in locals(): del df_code
                if 'df_kor' in locals(): del df_kor
                if 'doc' in locals(): doc.close()
                if 'dest_wb' in locals(): del dest_wb
                if 'output' in locals(): del output
                gc.collect()

                if new_files:
                    st.success("ì™„ë£Œ! ì¢Œí‘œ ê¸°ë°˜ ë¬¸ì¥ ë³µì› ë° ì •ë°€ ì •ì œ ì ìš©ë¨.")
        else:
            st.error("ëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

with col_right:
    st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    if st.session_state['converted_files']:
        for i, fname in enumerate(st.session_state['converted_files']):
            c1, c2 = st.columns([3, 1])
            with c1: st.text(f"ğŸ“„ {fname}")
            with c2:
                st.download_button(
                    label="ë°›ê¸°", 
                    data=st.session_state['download_data'][fname], 
                    file_name=fname, 
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=i
                )
